
import jsonlines
import logging
import torch

import copy

from dataset_iterators import *
from dataloading import *
from training import *

if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    device = torch.device('cpu')



################################################################################################
# Evaluations for language models (next-word prediction models)
################################################################################################
def sentence_negative_logprob(model, dataset, sentence, category=None):

    model.eval()

    inp = dataset.tokenizer([sentence], add_special_tokens=False)
    inp = dataset.prepare_input({"input_ids" : inp["input_ids"], "labels" : inp["input_ids"]})
    
    if category.startswith("priming_short"):
        end_length = 10
    elif category.startswith("priming_long"):
        end_length = 21

    if end_length is not None:
        new_labels = inp["labels"].tolist()
        for index in range(len(new_labels[0])-end_length):
            new_labels[0][index] = -100
        new_labels = torch.LongTensor(new_labels).to(device)
        inp["labels"] = new_labels

    outp = model(inp)

    logprob = outp["loss"]

    return logprob


def minimal_pair(model, dataset, unacceptable_sentence, acceptable_sentence, category=None):

    model.eval()

    inp_acc = dataset.tokenizer([acceptable_sentence], add_special_tokens=False)
    inp_unacc = dataset.tokenizer([unacceptable_sentence], add_special_tokens=False)

    inp_acc = dataset.prepare_input({"input_ids" : inp_acc["input_ids"], "labels" : inp_acc["input_ids"]})
    inp_unacc = dataset.prepare_input({"input_ids" : inp_unacc["input_ids"], "labels" : inp_unacc["input_ids"]})
    
    if category.startswith("recursion_intensifier"):
        end_length = 2
    elif category.startswith("recursion_poss") or category.startswith("recursion_pp"):
        end_length = 3
    else:
        end_length = None

    if end_length is not None:
        new_acc_labels = inp_acc["labels"].tolist()
        for index in range(len(new_acc_labels[0])-end_length):
            new_acc_labels[0][index] = -100
        new_acc_labels = torch.LongTensor(new_acc_labels).to(device)
        inp_acc["labels"] = new_acc_labels

        new_unacc_labels = inp_unacc["labels"].tolist()
        for index in range(len(new_unacc_labels[0])-end_length):
            new_unacc_labels[0][index] = -100
        new_unacc_labels = torch.LongTensor(new_unacc_labels).to(device)
        inp_unacc["labels"] = new_unacc_labels
    
    outp_acc = model(inp_acc)
    outp_unacc = model(inp_unacc)

    loss_acc = outp_acc["loss"]
    loss_unacc = outp_unacc["loss"]

    output_dict = {}
    output_dict["loss_good"] = loss_acc
    output_dict["loss_bad"] = loss_unacc
    
    if loss_acc < loss_unacc:
        output_dict["correct"] = True
    else:
        output_dict["correct"] = False

    return output_dict


# Logprob that the sequence has under a model
# Equal to -1 * loss * sequence length
def model_logprob(sequence, model, tokenizer, temperature=1.0):

    sequence = "<bos> " + sequence + " <ENDTOKEN>"
    inp = tokenizer([sequence], add_special_tokens=False)
    for key in inp:
        inp[key] = torch.LongTensor(inp[key]).to(device)
    inp["labels"] = inp["input_ids"].clone()

    outp = model(inp, temperature=temperature)
    loss = outp["loss"] * (len(sequence.split()) - 1)

    return -1*loss


def lm_precision_recall(model, dataset, top_p=1.00, cold_temperature=None, hot_temperature=1.0, n_samples=10000, sgd_lr=None, adam_lr=None, sgd_epochs=1, adam_epochs=100, return_last=False, tokenizer=None, full_dataset=None):

    # Counters for the strings generated by each model or language
    lm_counter = Counter()
    hyp_counter = Counter()
    memorization_counter = Counter()

    temp_model = copy.deepcopy(model)

    train = {"input_ids" : dataset["input_ids"], "labels" : dataset["labels"]}

    for seq in dataset["input_ids"]:
        elt = tokenizer.decode(seq, skip_special_tokens=True)
        memorization_counter[elt] += 1

    temp_model = simple_train_model(temp_model, dataset, sgd_lr=sgd_lr, adam_lr=adam_lr, sgd_epochs=sgd_epochs, adam_epochs=adam_epochs, return_last=return_last, full_dataset=full_dataset)

    all_strings = dataset["all_strings"]

    for seq, count in all_strings:
        hyp_counter[seq] = count

    for _ in range(n_samples // 1000):
        lm_text = sample_from_lm(temp_model, tokenizer, batch_size=1000, top_p=top_p, temperature=hot_temperature)
        lm_counter.update(lm_text)

    
    # Get the 25 most common tokens from the various generators
    lm_most_common = lm_counter.most_common(25)
    logging.info("LM most common: " + str(lm_most_common))

    if cold_temperature is not None:

        lm_scored = []

        for sequence in lm_counter:
            lm_scored.append((sequence, model_logprob(sequence, temp_model, tokenizer, temperature=cold_temperature).item()))

        lm_most_common = sorted(lm_scored, key=lambda x: -1*x[1])[:25]

    hyp_most_common = hyp_counter.most_common(25)
    memorization_most_common = memorization_counter.most_common(25)

    logging.info("LM most common: " + str(lm_most_common))

    lm_most_common = [x[0] for x in lm_most_common]
    hyp_most_common = [x[0] for x in hyp_most_common]
    memorization_most_common = [x[0] for x in memorization_most_common]


    # Compute precision and recall for LM and memorization
    lm_precision, lm_recall, lm_fscore, model_imprecise, model_irrecall = compute_precision_recall(lm_most_common, lm_counter, hyp_most_common, hyp_counter)
    memorization_precision, memorization_recall, memorization_fscore, _, _ = compute_precision_recall(memorization_most_common, memorization_counter, hyp_most_common, hyp_counter)


    logging.info("LM-generated common sequences that are ungrammatical:")
    logging.info(model_imprecise)
    logging.info("Grammatical sequences that the model is missing:")
    logging.info(model_irrecall)

    return lm_precision, lm_recall, lm_fscore, memorization_precision, memorization_recall, memorization_fscore


def sample_generation(dataset, trainer, n_positions=100):

    input_ids = dataset.tokenizer(["the"], add_special_tokens=False, return_tensors="pt").to(device)["input_ids"]

    # Pure sampling
    text = trainer.model.generate(input_ids, do_sample=True, max_length=n_positions, top_p=1.00, top_k=0, early_stopping=True, pad_token_id=dataset.tokenizer.pad_token_id, eos_token_id=-1)
    text = dataset.tokenizer.decode(text[0], skip_special_tokens=True)
    logging.info("Pure sampling:")
    logging.info(text)

    # Top-40
    text = trainer.model.generate(input_ids, do_sample=True, max_length=n_positions, top_p=1.00, top_k=40, early_stopping=True, pad_token_id=dataset.tokenizer.pad_token_id, eos_token_id=-1)
    text = dataset.tokenizer.decode(text[0], skip_special_tokens=True)
    logging.info("Top-40:")
    logging.info(text)


################################################################################################
# Minimal pair evals
################################################################################################

def zorro_eval(model, dataset):
    zorro_categories = ["agreement_determiner_noun-across_1_adjective",
            "agreement_determiner_noun-between_neighbors",
            "agreement_subject_verb-across_prepositional_phrase",
            "agreement_subject_verb-across_relative_clause",
            "agreement_subject_verb-in_question_with_aux",
            "agreement_subject_verb-in_simple_question",
            "anaphor_agreement-pronoun_gender",
            "argument_structure-dropped_argument",
            "argument_structure-swapped_arguments",
            "argument_structure-transitive",
            "binding-principle_a",
            "case-subjective_pronoun",
            "ellipsis-n_bar",
            "filler-gap-wh_question_object",
            "filler-gap-wh_question_subject",
            "irregular-verb",
            "island-effects-adjunct_island",
            "island-effects-coordinate_structure_constraint",
            "local_attractor-in_question_with_aux",
            "npi_licensing-matrix_question",
            "npi_licensing-only_npi_licensor",
            "quantifiers-existential_there",
            "quantifiers-superlative"
            ]

    total_correct = 0
    total_total = 0

    for category in zorro_categories:
        fi = open("Zorro/sentences/babyberta/" + category + ".txt", "r")

        pairs = []
        current_pair = []

        for line in fi:
            current_pair.append(line.strip())
            if len(current_pair) == 2:
                pairs.append(current_pair)
                current_pair = []

        correct = 0
        total = 0
        for pair in pairs:
            if minimal_pair(model, dataset, pair[0], pair[1], category=category)["correct"]:
                correct += 1

            total += 1

        total_correct += correct
        total_total += total

        logging.info("ZORRO MINIMAL PAIR RESULTS:" + category + " " + str(correct) + " " + str(total) + " " + str(correct*1.0/total))

    logging.info("ZORRO MINIMAL PAIR RESULTS: OVERALL: " + str(total_correct) + " " + str(total_total) + " " + str(total_correct*1.0/total_total))



# Add relevant spaces around apostrophes
def apostrophe_space(sentence):
    new_sentence = sentence.replace("n't", " n't")
    new_sentence = new_sentence.replace("ca n't", "can n't")
    return new_sentence

# Convert blimp sentences to a suitable format for our models
def blimp_postprocess(sentence):
    new_sentence = sentence[:]
    new_sentence = new_sentence[0].lower() + new_sentence[1:]
    new_sentence_end = new_sentence[-1]
    new_sentence = new_sentence[:-1] + " " + new_sentence_end
    new_sentence = apostrophe_space(new_sentence)
    return new_sentence

def blimp_eval(model, dataset):
    blimp_categories = ["adjunct_island",
                "anaphor_gender_agreement", 
                "anaphor_number_agreement", 
                "animate_subject_passive", 
                "animate_subject_trans",
                "causative",
                "complex_NP_island", 
                "coordinate_structure_constraint_complex_left_branch", 
                "coordinate_structure_constraint_object_extraction",
                "coordinate_structure_constraint_subject_extraction",
                "determiner_noun_agreement_1",
                "determiner_noun_agreement_2",
                "determiner_noun_agreement_irregular_1",
                "determiner_noun_agreement_irregular_2",
                "determiner_noun_agreement_with_adj_2",
                "determiner_noun_agreement_with_adjective_1",
                "determiner_noun_agreement_with_adj_irregular_1",
                "determiner_noun_agreement_with_adj_irregular_2",
                "distractor_agreement_relational_noun",
                "distractor_agreement_relative_clause",
                "drop_argument",
                "ellipsis_n_bar_1",
                "ellipsis_n_bar_2",
                "existential_there_object_raising",
                "existential_there_quantifiers_1",
                "existential_there_quantifiers_2",
                "existential_there_subject_raising",
                "expletive_it_object_raising",
                "inchoative",
                "intransitive",
                "irregular_past_participle_adjectives",
                "irregular_past_participle_verbs",
                "irregular_plural_subject_verb_agreement_1",
                "irregular_plural_subject_verb_agreement_2",
                "left_branch_island_echo_question",
                "left_branch_island_simple_question",
                "matrix_question_npi_licensor_present",
                "npi_present_1",
                "npi_present_2",
                "only_npi_licensor_present",
                "only_npi_scope",
                "passive_1",
                "passive_2",
                "principle_A_case_1",
                "principle_A_case_2",
                "principle_A_c_command",
                "principle_A_domain_1",
                "principle_A_domain_2",
                "principle_A_domain_3",
                "principle_A_reconstruction",
                "regular_plural_subject_verb_agreement_1",
                "regular_plural_subject_verb_agreement_2",
                "sentential_negation_npi_licensor_present",
                "sentential_negation_npi_scope",
                "sentential_subject_island",
                "superlative_quantifiers_1",
                "superlative_quantifiers_2",
                "tough_vs_raising_1",
                "tough_vs_raising_2",
                "transitive",
                "wh_island",
                "wh_questions_object_gap",
                "wh_questions_object_gap_long_distance",
                "wh_questions_subject_gap",
                "wh_questions_subject_gap_long_distance",
                "wh_vs_that_no_gap",
                "wh_vs_that_no_gap_long_distance",
                "wh_vs_that_with_gap",
                "wh_vs_that_with_gap_long_distance"
            ]

    total_correct = 0
    total_total = 0

    for category in blimp_categories:
        pairs = []

        with jsonlines.open("blimp_childes/" + category + ".jsonl") as reader:
            for obj in reader:
                pair = [blimp_postprocess(obj["sentence_bad"]), blimp_postprocess(obj["sentence_good"])]
                pairs.append(pair)

        correct = 0
        total = 0
        for pair in pairs:
            if minimal_pair(model, dataset, pair[0], pair[1], category=category)["correct"]:
                correct += 1

            total += 1

        total_correct += correct
        total_total += total

        logging.info("BLIMP_CHILDES MINIMAL PAIR RESULTS:" + category + " " + str(correct) + " " + str(total) + " " + str(correct*1.0/total))

    logging.info("BLIMP_CHILDES MINIMAL PAIR RESULTS: OVERALL: " + str(total_correct) + " " + str(total_total) + " " + str(total_correct*1.0/total_total))



def scamp_eval(model, dataset, plausible=True):
    if plausible:
        categories = ["anaphor_gender_agreement", "anaphor_number_agreement", "matrix_question_npi_licensor_present", "npi_present", "only_npi_licensor_present", "sentential_negation_npi_licensor_present", "only_npi_scope", "sentential_negation_npi_scope", "intransitive", "transitive", "left_branch_island_simple_question", "coordinate_structure_constrain_object_extraction", "wh_island", "complex_np_island", "adjunct_island", "wh_vs_that_with_gap_long_distance", "wh_vs_that_with_gap", "wh_vs_that_no_gap_long_distance", "wh_vs_that_no_gap", "wh_questions_subject_gap_long_distance", "wh_questions_object_gap_long_distance", "wh_questions_subject_gap", "wh_questions_object_gap", "principle_A_domain_3", "principle_A_domain_2", "principle_A_domain_1", "principle_A_c_command", "subj_aux_vary_subj", "subj_aux_vary_verb", "subj_aux_vary_verb_rc", "subj_aux_vary_verb_pp", "subj_verb_vary_verb", "subj_aux_agreement_question_vary_subj", "subj_aux_agreement_question_vary_aux", "determiner_noun_agreement_1", "determiner_noun_agreement_adj_1", "determiner_noun_agreement_2", "determiner_noun_agreement_adj_2", "svo_vos", "green_ideas", "adv_order", "pp_order", "center_embedding_single_1", "center_embedding_single_2", "center_embedding_double_1", "center_embedding_double_2", "swapped_ditransitive_1", "swapped_ditransitive_2", "ellipsis", "recursion_intensifier_adj_short", "recursion_intensifier_adv_short", "recursion_pp_verb_short", "recursion_pp_is_short", "recursion_poss_transitive_short", "recursion_poss_ditransitive_short", "recursion_intensifier_adj_medium", "recursion_intensifier_adv_medium", "recursion_pp_verb_medium", "recursion_pp_is_medium", "recursion_poss_transitive_medium", "recursion_poss_ditransitive_medium", "recursion_intensifier_adj_long", "recursion_intensifier_adv_long", "recursion_pp_verb_long", "recursion_pp_is_long", "recursion_poss_transitive_long", "recursion_poss_ditransitive_long"]
    else:
        categories = ['anaphor_gender_agreement_implausible', 'anaphor_number_agreement_implausible', 'matrix_question_npi_licensor_present_implausible', 'npi_present_implausible', 'only_npi_licensor_present_implausible', 'sentential_negation_npi_licensor_present_implausible', 'only_npi_scope_implausible', 'sentential_negation_npi_scope_implausible', 'intransitive_implausible', 'transitive_implausible', 'left_branch_island_simple_question_implausible', 'coordinate_structure_constrain_object_extraction_implausible', 'wh_island_implausible', 'complex_np_island_implausible', 'adjunct_island_implausible', 'wh_vs_that_with_gap_long_distance_implausible', 'wh_vs_that_with_gap_implausible', 'wh_vs_that_no_gap_long_distance_implausible', 'wh_vs_that_no_gap_implausible', 'wh_questions_subject_gap_long_distance_implausible', 'wh_questions_object_gap_long_distance_implausible', 'wh_questions_subject_gap_implausible', 'wh_questions_object_gap_implausible', 'principle_A_domain_3_implausible', 'principle_A_domain_2_implausible', 'principle_A_domain_1_implausible', 'principle_A_c_command_implausible', 'subj_aux_vary_subj_implausible', 'subj_aux_vary_verb_implausible', 'subj_aux_vary_verb_rc_implausible', 'subj_aux_vary_verb_pp_implausible', 'subj_verb_vary_verb_implausible', 'subj_aux_agreement_question_vary_subj_implausible', 'subj_aux_agreement_question_vary_aux_implausible', 'determiner_noun_agreement_1_implausible', 'determiner_noun_agreement_adj_1_implausible', 'determiner_noun_agreement_2_implausible', 'determiner_noun_agreement_adj_2_implausible', 'svo_vos_implausible', 'green_ideas_implausible', 'adv_order_implausible', 'pp_order_implausible', 'center_embedding_single_1_implausible', 'center_embedding_single_2_implausible', 'center_embedding_double_1_implausible', 'center_embedding_double_2_implausible', 'swapped_ditransitive_1_implausible', 'swapped_ditransitive_2_implausible', 'ellipsis_implausible', 'recursion_intensifier_adj_short_implausible', 'recursion_intensifier_adv_short_implausible', 'recursion_pp_verb_short_implausible', 'recursion_pp_is_short_implausible', 'recursion_poss_transitive_short_implausible', 'recursion_poss_ditransitive_short_implausible', 'recursion_intensifier_adj_medium_implausible', 'recursion_intensifier_adv_medium_implausible', 'recursion_pp_verb_medium_implausible', 'recursion_pp_is_medium_implausible', 'recursion_poss_transitive_medium_implausible', 'recursion_poss_ditransitive_medium_implausible', 'recursion_intensifier_adj_long_implausible', 'recursion_intensifier_adv_long_implausible', 'recursion_pp_verb_long_implausible', 'recursion_pp_is_long_implausible', 'recursion_poss_transitive_long_implausible', 'recursion_poss_ditransitive_long_implausible']
    
    categories = sorted(categories)

    total_correct = 0
    total_total = 0

    for category in categories:
        if plausible:
            fi = open("scamp/scamp_plausible/" + category + ".tsv", "r")
        else:
            fi = open("scamp/scamp_implausible/" + category + ".tsv", "r")

        pairs = []

        for line in fi:
            parts = line.strip().split("\t")
            
            # Ungrammatical first, then grammatical
            pairs.append([parts[1], parts[0]])

        correct = 0
        total = 0
        for pair in pairs:
            if minimal_pair(model, dataset, pair[0], pair[1], category=category)["correct"]:
                correct += 1

            total += 1

        total_correct += correct
        total_total += total

        if plausible:
            logging.info("SCAMP PLAUSIBLE MINIMAL PAIR RESULTS:" + category + " " + str(correct) + " " + str(total) + " " + str(correct*1.0/total))
        else:
            logging.info("SCAMP IMPLAUSIBLE MINIMAL PAIR RESULTS:" + category + " " + str(correct) + " " + str(total) + " " + str(correct*1.0/total))

    if plausible:
        logging.info("SCAMP PLAUSIBLE MINIMAL PAIR RESULTS: OVERALL: " + str(total_correct) + " " + str(total_total) + " " + str(total_correct*1.0/total_total))
    else:
        logging.info("SCAMP IMPLAUSIBLE MINIMAL PAIR RESULTS: OVERALL: " + str(total_correct) + " " + str(total_total) + " " + str(total_correct*1.0/total_total))




def recursion_eval(model, dataset):
    categories = ['recursion_intensifier_adj_0', 'recursion_intensifier_adj_1', 'recursion_intensifier_adj_2', 'recursion_intensifier_adj_3', 'recursion_intensifier_adj_4', 'recursion_intensifier_adj_5', 'recursion_intensifier_adj_6', 'recursion_intensifier_adj_7', 'recursion_intensifier_adj_8', 'recursion_intensifier_adj_9', 'recursion_intensifier_adj_10', 'recursion_intensifier_adv_0', 'recursion_intensifier_adv_1', 'recursion_intensifier_adv_2', 'recursion_intensifier_adv_3', 'recursion_intensifier_adv_4', 'recursion_intensifier_adv_5', 'recursion_intensifier_adv_6', 'recursion_intensifier_adv_7', 'recursion_intensifier_adv_8', 'recursion_intensifier_adv_9', 'recursion_intensifier_adv_10', 'recursion_pp_verb_0', 'recursion_pp_verb_1', 'recursion_pp_verb_2', 'recursion_pp_verb_3', 'recursion_pp_verb_4', 'recursion_pp_verb_5', 'recursion_pp_verb_6', 'recursion_pp_verb_7', 'recursion_pp_verb_8', 'recursion_pp_verb_9', 'recursion_pp_verb_10', 'recursion_pp_is_0', 'recursion_pp_is_1', 'recursion_pp_is_2', 'recursion_pp_is_3', 'recursion_pp_is_4', 'recursion_pp_is_5', 'recursion_pp_is_6', 'recursion_pp_is_7', 'recursion_pp_is_8', 'recursion_pp_is_9', 'recursion_pp_is_10', 'recursion_poss_transitive_0', 'recursion_poss_transitive_1', 'recursion_poss_transitive_2', 'recursion_poss_transitive_3', 'recursion_poss_transitive_4', 'recursion_poss_transitive_5', 'recursion_poss_transitive_6', 'recursion_poss_transitive_7', 'recursion_poss_transitive_8', 'recursion_poss_transitive_9', 'recursion_poss_transitive_10', 'recursion_poss_ditransitive_0', 'recursion_poss_ditransitive_1', 'recursion_poss_ditransitive_2', 'recursion_poss_ditransitive_3', 'recursion_poss_ditransitive_4', 'recursion_poss_ditransitive_5', 'recursion_poss_ditransitive_6', 'recursion_poss_ditransitive_7', 'recursion_poss_ditransitive_8', 'recursion_poss_ditransitive_9', 'recursion_poss_ditransitive_10', 
            'recursion_intensifier_adj_0_implausible', 'recursion_intensifier_adj_1_implausible', 'recursion_intensifier_adj_2_implausible', 'recursion_intensifier_adj_3_implausible', 'recursion_intensifier_adj_4_implausible', 'recursion_intensifier_adj_5_implausible', 'recursion_intensifier_adj_6_implausible', 'recursion_intensifier_adj_7_implausible', 'recursion_intensifier_adj_8_implausible', 'recursion_intensifier_adj_9_implausible', 'recursion_intensifier_adj_10_implausible', 'recursion_intensifier_adv_0_implausible', 'recursion_intensifier_adv_1_implausible', 'recursion_intensifier_adv_2_implausible', 'recursion_intensifier_adv_3_implausible', 'recursion_intensifier_adv_4_implausible', 'recursion_intensifier_adv_5_implausible', 'recursion_intensifier_adv_6_implausible', 'recursion_intensifier_adv_7_implausible', 'recursion_intensifier_adv_8_implausible', 'recursion_intensifier_adv_9_implausible', 'recursion_intensifier_adv_10_implausible', 'recursion_pp_verb_0_implausible', 'recursion_pp_verb_1_implausible', 'recursion_pp_verb_2_implausible', 'recursion_pp_verb_3_implausible', 'recursion_pp_verb_4_implausible', 'recursion_pp_verb_5_implausible', 'recursion_pp_verb_6_implausible', 'recursion_pp_verb_7_implausible', 'recursion_pp_verb_8_implausible', 'recursion_pp_verb_9_implausible', 'recursion_pp_verb_10_implausible', 'recursion_pp_is_0_implausible', 'recursion_pp_is_1_implausible', 'recursion_pp_is_2_implausible', 'recursion_pp_is_3_implausible', 'recursion_pp_is_4_implausible', 'recursion_pp_is_5_implausible', 'recursion_pp_is_6_implausible', 'recursion_pp_is_7_implausible', 'recursion_pp_is_8_implausible', 'recursion_pp_is_9_implausible', 'recursion_pp_is_10_implausible', 'recursion_poss_transitive_0_implausible', 'recursion_poss_transitive_1_implausible', 'recursion_poss_transitive_2_implausible', 'recursion_poss_transitive_3_implausible', 'recursion_poss_transitive_4_implausible', 'recursion_poss_transitive_5_implausible', 'recursion_poss_transitive_6_implausible', 'recursion_poss_transitive_7_implausible', 'recursion_poss_transitive_8_implausible', 'recursion_poss_transitive_9_implausible', 'recursion_poss_transitive_10_implausible', 'recursion_poss_ditransitive_0_implausible', 'recursion_poss_ditransitive_1_implausible', 'recursion_poss_ditransitive_2_implausible', 'recursion_poss_ditransitive_3_implausible', 'recursion_poss_ditransitive_4_implausible', 'recursion_poss_ditransitive_5_implausible', 'recursion_poss_ditransitive_6_implausible', 'recursion_poss_ditransitive_7_implausible', 'recursion_poss_ditransitive_8_implausible', 'recursion_poss_ditransitive_9_implausible', 'recursion_poss_ditransitive_10_implausible']
    
    categories = sorted(categories)

    total_correct = 0
    total_total = 0

    for category in categories:
        fi = open("scamp/recursion/" + category + ".tsv", "r")

        pairs = []

        for line in fi:
            parts = line.strip().split("\t")
            pairs.append([parts[1], parts[0]])

        correct = 0
        total = 0
        for pair in pairs:
            if minimal_pair(model, dataset, pair[0], pair[1], category=category)["correct"]:
                correct += 1

            total += 1

        total_correct += correct
        total_total += total

        logging.info("RECURSION MINIMAL PAIR RESULTS:" + category + " " + str(correct) + " " + str(total) + " " + str(correct*1.0/total))

    logging.info("RECURSION MINIMAL PAIR RESULTS: OVERALL: " + str(total_correct) + " " + str(total_total) + " " + str(total_correct*1.0/total_total))


def priming_eval(model, dataset):
    categories = ["priming_short", "priming_short_implausible", "priming_long", "priming_long_implausible"]
    
    categories = sorted(categories)


    for category in categories:
        total_logprob_single = 0
        total_logprob_double = 0
        total_perplexity_single = 0
        total_perplexity_double = 0
        count = 0
        
        fi = open("scamp/priming/" + category + ".tsv", "r")

        pairs = []

        for line in fi:
            count += 1
            parts = line.strip().split("\t")
            logprob_single = sentence_negative_logprob(model, dataset, parts[0], category=category)
            logprob_double = sentence_negative_logprob(model, dataset, parts[1], category=category)

            total_logprob_single += logprob_single
            total_logprob_double += logprob_double

            total_perplexity_single += math.exp(logprob_single)
            total_perplexity_double += math.exp(logprob_double)

        logging.info(category + " AVG SINGLE NEGATIVE LOGPROB: " + str(round((total_logprob_single/count).item(), 3)))
        logging.info(category + " AVG DOUBLE NEGATIVE LOGPROB: " + str(round((total_logprob_double/count).item(), 3)))

        logging.info(category + " AVG SINGLE PERPLEXITY: " + str(round((total_perplexity_single/count), 3)))
        logging.info(category + " AVG DOUBLE PERPLEXITY: " + str(round((total_perplexity_double/count), 3)))
 





################################################################################################
# Evaluations for meta language models
################################################################################################


def eval_formal(model, language_list, formal_train_size=None, formal_test_size=None, meta_train_batch_size=None, n_positions=None, top_p=None, hot_temperature=None, cold_temperature=None, prec_rec_n_samples=None, inner_lr=None, adam_lr=5e-4, sgd_epochs=None, adam_epochs=None, return_last=None, integer_vocab_size=None, tokenizer=None):
    if language_list == "language_list":
        n_langs = 56
    elif language_list == "language_list_simplified":
        n_langs = 20
    elif language_list == "validation_languages":
        n_langs = 20

    yandp_dataset = formal_dataset(language_list, training_size=formal_train_size, test_size=formal_test_size, batch_size=meta_train_batch_size)
    
    yandp_meta_dataset = MetaLMDataset(create_dataset=yandp_dataset, meta_train_size=0, meta_valid_size=0, meta_test_size=n_langs, integer_vocab_size=integer_vocab_size, context_size=n_positions)

    total_lm_precision = 0
    total_lm_recall = 0
    total_lm_fscore = 0

    total_mem_precision = 0
    total_mem_recall = 0
    total_mem_fscore = 0

    denom = 0


    for inputs in yandp_meta_dataset.test:
        logging.info("Language: " + inputs["name"])
        logging.info("Description: " + inputs["description"])
        lm_precision, lm_recall, lm_fscore, mem_precision, mem_recall, mem_fscore = lm_precision_recall(model, inputs, top_p=top_p, hot_temperature=hot_temperature, cold_temperature=cold_temperature, n_samples=prec_rec_n_samples, sgd_lr=inner_lr, adam_lr=adam_lr, sgd_epochs=sgd_epochs, adam_epochs=adam_epochs, return_last=return_last, tokenizer=tokenizer, full_dataset=yandp_meta_dataset)

        total_lm_precision += lm_precision
        total_lm_recall += lm_recall
        total_lm_fscore += lm_fscore

        total_mem_precision += mem_precision
        total_mem_recall += mem_recall
        total_mem_fscore += mem_fscore

        denom += 1

        logging.info("LM precision, recall, fscore: " + str(lm_precision) + " " + str(lm_recall) + " " + str(lm_fscore))
        logging.info("Memorization precision, recall, fscore: " + str(mem_precision) + " " + str(mem_recall) + " " + str(mem_fscore))
        logging.info("")

    logging.info("Average LM Y&P precision: " + str(total_lm_precision / denom))
    logging.info("Average LM Y&P recall: " + str(total_lm_recall / denom))
    logging.info("Average LM Y&P F-score: " + str(total_lm_fscore / denom))
    logging.info("")
    logging.info("Average memorization Y&P precision: " + str(total_mem_precision / denom))
    logging.info("Average memorization Y&P recall: " + str(total_mem_recall / denom))
    logging.info("Average memorization Y&P F-score: " + str(total_mem_fscore / denom))
    logging.info("")







